---
title: "Summary of List Experiment"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(data.table)
library(dplyr)
library(tidyverse)
library(list)
library(car)
library(boot)
library(openxlsx)
library(ggplot2)
library(colorBlindness)

rm(list = ls())
set.seed(1201202)
setwd("/local/home/yufenlai/working_paper/carbon")

################################################################################
### Define functions
################################################################################

### make summary table
make_summary <-
    function(est) {
        tbl_temp <-
            lapply(
                1:n_ss,
                function(i) {
                    par <- est$par.treat[[i]]
                    se <- est$se.treat[[i]]
                    p <- 2 * (1 - pnorm(abs(par / se)))
                    star <- ifelse(
                        p < 0.01,
                        "***",
                        ifelse(
                            p < 0.05,
                            "**",
                            ifelse(p < 0.1, "*", "")
                        )
                    )
                    variable <- names(par)

                    names(par) <- NULL
                    names(se) <- NULL
                    names(p) <- NULL
                    names(star) <- NULL

                    return(
                        data.frame(
                            statement = statement_reference$statement[statement_reference$treatment == i],
                            variable = variable,
                            coefficient = par,
                            SE = se,
                            p = p,
                            star = star
                        )
                    )
                }
            )
        tbl_temp <- do.call(rbind, tbl_temp)
        return(tbl_temp)
    }

### calculate the average percentage of answering yes to sensitive statements
# for each treatment and list_id, calculate a bootstrapped count of treatment group - control group
# record the number of respondents assigned to each list_id
# for each treatment group, calculate the weighted average percentage of yes responses and the standard error

boot_mean <- 
    function(treatment, list_id, count, data, n_boot = 1000) {
        # all unique treatment groups
        treatment_groups <- unique(data$treatment)
        treatment_groups <- treatment_groups[treatment_groups != 0]
        treatment_groups <- treatment_groups[order(treatment_groups)]
        # all unique list_ids
        list_ids <- unique(data$list_id)
        
        # for each treatment group
        boot <- 
            lapply(
                treatment_groups,
                function(t) {
                    # for each list_id
                    boot_list <- 
                        lapply(
                            list_ids,
                            function(l) {
                                # get the data for the treatment group and list_id
                                data_treatment <- data[data$treatment == t & data$list_id == l, ]
                                # get the number of respondents assigned to the treatment group and list_id
                                n_treatment <- nrow(data_treatment)
                                # get the number of respondents assigned to the control group and list_id
                                data_control <- data[data$list_id == l & data$treatment == 0, ]
                                n_control <- nrow(data_control)
                                # calculate the bootstrapped count of treatment group - control group
                                boot_count <- 
                                    replicate(
                                        n_boot,
                                        mean(sample(data_treatment$count, n_treatment, replace = TRUE)) - 
                                            mean(sample(data_control$count, n_control, replace = TRUE))
                                    )
                                
                                boot_summary <- 
                                    data.frame(
                                        treatment = t,
                                        list_id = l,
                                        mean = mean(boot_count),
                                        sd = sd(boot_count),
                                        n_treatment = n_treatment,
                                        n_control = n_control
                                    )
                                return(boot_summary)
                            }
                        )
                    # combine the results for each list_id
                    boot_list <- do.call(rbind, boot_list)
                    return(boot_list)
                }
            )
        # combine the results for each treatment group
        boot <- do.call(rbind, boot)
        # calculate the weighted average percentage of yes responses and the standard error
        boot_summary <- 
            boot %>%
            group_by(treatment) %>%
            summarise(
                mean = sum(mean * n_treatment) / sum(n_treatment),
                sd = sqrt(
                    sum(
                        sd^2 * (n_treatment / sum(n_treatment))^2
                    )
                )
            )
        return(
            list(
                "boot" = boot,
                "boot_summary" = boot_summary
            )
        )
    }

################################################################################
### Read in data
################################################################################
message("Reading in data...")
load("./image/sensitive_statements.RData")
dt_count <- fread("csv/dt_counts.csv")

### treatment reference
statement_reference <-
    dt_count %>%
    select(
        treatment,
        statement
    ) %>%
    distinct() %>%
    arrange(treatment) %>%
    mutate(
        statement = case_when(
            treatment == 0 ~ "Control List",
            treatment == 1 ~ "Restricting electricity",
            treatment == 2 ~ "Carbon tax",
            treatment == 3 ~ "Not commit zero emissions",
            treatment == 4 ~ "Mandatory energy efficiency"
        )
    )

### number of control lists
n_cl <- dt_count %>%
    select(list_id) %>%
    distinct() %>%
    nrow()

### n control statements
n_cs <- 4

### number of sensitive statements
n_ss <- dt_count %>%
    select(statement) %>%
    distinct() %>%
    filter(statement != "") %>%
    nrow()
```

## Validating the floor and ceiling of treatment groups
This step validates if the list experiment is working as intended.
Selecting floor or ceiling counts (namely, 0 or 5) for the treatment groups
will reveal the answer to the sensitive question.
The below plot shows that the floor and ceiling all combined is around 10%
of the total responses for each treatment group,
which should be comparable to the existing literature if not lower.

```{r validate_floor_ceiling, echo=FALSE, message = FALSE}
dt_count %>%
    filter(treatment != 0) %>%
    group_by(list_id, treatment, count) %>%
    summarise(n = n_distinct(ResponseId)) %>%
    ungroup() %>%
    group_by(list_id, treatment) %>%
    mutate(
        pct = n / sum(n),
        list_id = as.factor(list_id),
        treatment = case_when(
            treatment == 1 ~ "1 - Restricting electricity",
            treatment == 2 ~ "2 - Carbon tax",
            treatment == 3 ~ "3 - Not commit zero emissions",
            treatment == 4 ~ "4 - Mandatory energy efficiency"
        )
    ) %>%
    arrange(treatment, list_id, count) %>%
    # bar plot of density for each treatment and group by list_id
    ggplot(
        aes(
            x = count,
            y = pct,
            group = list_id
        )
    ) +
    geom_bar(
        stat = "identity",
        aes(fill = list_id),
        position = "dodge"
    ) +
    # show all values on x-axis
    scale_x_continuous(breaks = seq(0, n_cs + 1, 1)) +
    # display all treatment groups in order
    facet_wrap(vars(treatment)) +
    # set color theme
    scale_fill_manual(values = Blue2DarkRed12Steps) +
    # scale y-axis to percentage
    scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
    # set x-axis label
    labs(
        x = "Count",
        y = "Percentage of Yes Responses",
        title = "Distribution of Floor and Ceiling Counts by Treatment Group"
    ) +
    # change legend title
    guides(fill = guide_legend(title = "List ID")) +
    theme_classic()
    
```

## Overall percentage of support for sensitive statements
```{r overall_percentage, echo=FALSE, message = FALSE}
pct_boot <- 
    boot_mean(
        treatment = "treatment",
        list_id = "list_id",
        count = "count",
        data = dt_count
    )
```

Below table shows the percentage of "yes" for each sensitive statement by control list:

```{r overall_percentage_summary, echo=FALSE, message = FALSE}
pct_boot$boot %>%
    mutate(
        treatment = case_when(
            treatment == 1 ~ "1 - Restricting electricity",
            treatment == 2 ~ "2 - Carbon tax",
            treatment == 3 ~ "3 - Not commit zero emissions",
            treatment == 4 ~ "4 - Mandatory energy efficiency"
        )
    ) %>%
    select(
        treatment,
        list_id,
        mean,
        sd
    )
```

A plot of the above table. There appears to be some degrees of design effects, namely, the percentage of "yes" responses for the sensitive statements varies by the control list.
However, there is not clear pattern that suggest a particular list more likely to get "yes" responses.

```{r overall_percentage_summary_plot, echo=FALSE, message = FALSE}
pct_boot$boot %>%
    mutate(
        treatment = case_when(
            treatment == 1 ~ "1 - Restricting electricity",
            treatment == 2 ~ "2 - Carbon tax",
            treatment == 3 ~ "3 - Not commit zero emissions",
            treatment == 4 ~ "4 - Mandatory energy efficiency"
        ),
        list_id = as.factor(list_id)
    ) %>%
    ggplot(aes(x = treatment, y = mean, group = list_id)) +
    # bar plot of mean for each treatment and group by list_id
    geom_bar(stat = "identity", aes(fill = list_id), position = "dodge") +
    # set color theme
    scale_fill_manual(values = Blue2DarkRed12Steps) +
    # scale y-axis to percentage
    scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
    # set x-axis label
    labs(
        x = "Treatment Group",
        y = "Percentage of Yes Responses",
        title = "Overall Percentage of Support for Sensitive Statements"
    ) +
    # change legend title
    guides(fill = guide_legend(title = "List ID")) +
    theme_classic() +
    # rotate x-axis labels
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

A plot of the average mean and 95% confidence level error bar for sensitive statement:

```{r overall_percentage_plot, echo=FALSE, message = FALSE}
pct_boot$boot_summary %>%
    mutate(
        treatment = case_when(
            treatment == 1 ~ "1 - Restricting electricity",
            treatment == 2 ~ "2 - Carbon tax",
            treatment == 3 ~ "3 - Not commit zero emissions",
            treatment == 4 ~ "4 - Mandatory energy efficiency"
        )
    ) %>%
    ggplot(aes(x = treatment, y = mean)) +
    geom_bar(stat = "identity", fill = "#0072B2") +
    geom_errorbar(aes(ymin = mean - 1.96* sd, ymax = mean + 1.96 * sd), width = 0.1) +
    scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
    labs(
        x = "Treatment Group",
        y = "Percentage of Yes Responses",
        title = "Overall Percentage of Support for Sensitive Statements"
    ) +
    # add percentage labels
    geom_text(aes(label = paste0(round(mean * 100, 1), "%")), vjust = -0.5) +
    theme_classic() +
    # rotate x-axis labels
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

## A intercept only model
The estimated probability of answering "yes" to the sensitive statements is the inverse logit of the coefficient.
The below table shows the estimated probability of answering "yes" to the sensitive statements by control list.
The results are consistent with the overall percentage of support for sensitive statements.
The standard errors of the control list effects were calculated using the delta method.

```{r intercept_only_model, echo=FALSE, message = FALSE}
################################################################################
### run list experiment, intercept only
################################################################################
message("Running list experiment, intercept only...")
ict_fit_intercept <-
    ictreg(
        count ~ as.factor(list_id) - 1,
        data = dt_count,
        treat = "treatment",
        J = n_cs,
        constrained = TRUE
    )

### make table
tbl_intercept <-
    lapply(
        1:n_ss,
        function(i) {
            par <- ict_fit_intercept$par.treat[[i]]
            se <- ict_fit_intercept$se.treat[[i]]
            control <- paste0("Control List ", 1:4)

            names(par) <- NULL
            names(se) <- NULL
            names(control) <- NULL

            data.frame(
                control = control,
                coefficient = par,
                SE = se
            ) %>%
                mutate(
                    treatment = i
                )
        }
    )

tbl_intercept <-
    do.call(rbind, tbl_intercept) %>%
    as.data.frame() %>%
    left_join(
        statement_reference
    ) %>%
    mutate(
        Prob. = inv.logit(coefficient)
    ) %>%
    select(
        statement,
        control,
        Prob.,
        coefficient,
        SE
    )

### use delta method to estimate the average treatment effect across control lists
# construct formulas
delta_f <-
    lapply(
        1:n_ss,
        function(i) {
            formula <-
                paste0(
                    "`sensitive.",
                    i,
                    ".as.factor(list_id)",
                    1:n_cl,
                    "`"
                )
            formula <- paste0(formula, collapse = " + ")
            formula <- paste0("(", formula, ") / ", n_cl)
            return(formula)
        }
    )

# estimate average treatment effect
tbl_ate <-
    lapply(
        1:length(delta_f),
        function(i) {
            statement <-
                statement_reference$statement[
                    statement_reference$treatment == i
                ]

            f <- delta_f[[i]]

            ate_est <-
                deltaMethod(
                    ict_fit_intercept,
                    f
                )

            return(
                data.frame(
                    statement = statement,
                    control = "Average",
                    coefficient = ate_est$Estimate,
                    SE = ate_est$SE
                ) %>%
                    mutate(
                        Prob. = inv.logit(coefficient)
                    ) %>%
                    select(
                        statement,
                        control,
                        Prob.,
                        coefficient,
                        SE
                    )
            )
        }
    )
tbl_ate <- do.call(rbind, tbl_ate)

### combine tables
tbl_intercept <-
    rbind(
        tbl_intercept,
        tbl_ate
    )

tbl_intercept
```

However, there seems to be some degree of design effects.
Also, the design effects seems more pronounced for the sensitive statement 1, i.e., restricting electricity, than the others.
The table below shows the p-value of the effect of control list on the probability of answering "yes" to the sensitive statements relative to each other.
For example, the first row shows the effect of control list 1 minus the effect of control list 1, 2, 3, and 4 for each sensitive statement.
The p-value is calculated using the delta method.

```{r intercept_only_model_pvalue, echo=FALSE, message = FALSE}
### delta method for testing if there is a variation in treatment effect across control lists
# construct formulas
design_effect <-
    lapply(
        1:n_ss,
        function(x) {
            effects <-
                paste0(
                    "`sensitive.",
                    x,
                    ".as.factor(list_id)",
                    1:n_cl,
                    "`"
                )

            formula <-
                lapply(
                    1:n_cl,
                    function(y) {
                        ### create formula for each permutation
                        paste0(
                            effects[y],
                            " - ",
                            effects[-y]
                        )
                    }
                )

            ### matrix to store delta method Estimates
            delta_estimates <-
                matrix(
                    NA,
                    nrow = n_cl,
                    ncol = n_cl
                )

            ### matrix to store delta method SE
            delta_se <-
                matrix(
                    NA,
                    nrow = n_cl,
                    ncol = n_cl
                )

            ### matrix to store delta method p-value
            delta_p <-
                matrix(
                    NA,
                    nrow = n_cl,
                    ncol = n_cl
                )

            for (i in 1:n_cl) {
                for (j in 1:n_cl) {
                    if (i < j) { ### upper triangle
                        f <- formula[[i]][j - 1]

                        delta_est <-
                            deltaMethod(
                                ict_fit_intercept,
                                f
                            )

                        delta_estimates[i, j] <- delta_est$Estimate
                        delta_se[i, j] <- delta_est$SE
                        delta_p[i, j] <- 2 * (1 - pnorm(abs(delta_est$Estimate / delta_est$SE)))
                    } else {
                        if (i == j) { ### diagonal
                            delta_estimates[i, j] <- 0
                            delta_se[i, j] <- 0
                            delta_p[i, j] <- 1
                        } else { ### lower triangle
                            f <- formula[[i]][j]

                            delta_est <-
                                deltaMethod(
                                    ict_fit_intercept,
                                    f
                                )

                            delta_estimates[i, j] <- delta_est$Estimate
                            delta_se[i, j] <- delta_est$SE
                            delta_p[i, j] <- 2 * (1 - pnorm(abs(delta_est$Estimate / delta_est$SE)))
                        }
                    }

                    ### combine into a data frame
                    colnames(delta_estimates) <- paste0("vs. Control List ", 1:n_cl, ", Estimate")
                    colnames(delta_se) <- paste0("vs. Control List ", 1:n_cl, ", SE")
                    colnames(delta_p) <- paste0("vs. Control List ", 1:n_cl, ", p-value")
                }
            }

            return(
                data.frame(
                    statement =
                        statement_reference$statement[
                            statement_reference$treatment == x
                        ],
                    control_list = paste0("Control List ", 1:n_cl)
                ) %>%
                    cbind(
                        as.data.frame(delta_estimates),
                        as.data.frame(delta_se),
                        as.data.frame(delta_p)
                    )
            )
        }
    )
design_effect <- do.call(rbind, design_effect)

design_effect %>%
    as.data.frame() %>%
    select(
        statement,
        control_list,
        contains("p-value")
    ) %>%
    # for each p value, round to 3 decimal places
    # if p value is less than 0.001, set to "< 0.001"
    # also add star to the p value
    # if p value is less than 0.01, add "***"
    # if p value is less than 0.05, add "**"
    # if p value is less than 0.1, add "*"
    mutate(
        across(
            contains("p-value"),
            ~ ifelse(. < 0.001, "< 0.001", round(., 3))
        ),
        across(
            contains("p-value"),
            ~ ifelse(. < 0.01, paste0(., "***"), .)
        ),
        across(
            contains("p-value"),
            ~ ifelse(. < 0.05 & . >= 0.01, paste0(., "**"), .)
        ),
        across(
            contains("p-value"),
            ~ ifelse(. < 0.1 & . >= 0.05, paste0(., "*"), .)
        ),
        across(
            contains("p-value"),
            ~ ifelse(. == 1, "-", .)
        )
    )
```
